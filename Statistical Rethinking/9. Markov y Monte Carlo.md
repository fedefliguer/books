## 9. CADENAS DE MARKOV Y MONTECARLO

* :gem: En la mitología muchas veces se oponen el azar y la sabiduría: las diosas romanas de Fortuna y Minerva son ejemplo de esto. Sin embargo, la estimación de distribuciones posteriores usando Cadenas de Markov de Monte Carlo (MCMC) es un ejemplo de la posibilidad de cooperación.

### 9.1. El Rey Markov y su reinado.

* La historia del Rey Markov y el Algoritmo de Metropolis es un ejemplo de cómo utilizar el azar ayuda a dar con la distribución correcta.
* Tenemos en este tipo de problemas tres cosas: objetivos de parámetros, probabilidades posteriores de cada valor del parámetro, y muestras tomadas de la distribución conjunta de los parámetros. El algoritmo de Metrópolis es un ejemplo, una versión más general es el muestreo de Gibbs. Esta es una secuencia de observaciones que se aproximan a partir de una distribución de probabilidad multivariante específica, cuando el muestreo directo es difícil. Tanto el algoritmo de Metrópolis como el de Gibbs no son eficientes con miles de perámetros. La razón es que tienden a atascarse en pequeñas regiones de la parte posterior, potencialmente por mucho tiempo.

### 9.2. Monte Carlo Hamiltoniano.

* El algoritmo de Metropolis y el muestreo de Gibbs son procedimientos altamente aleatorios. Intentan elaborar nuevos valores de parámetros (propuestas) y ver qué tan buenos son, en comparación con los valores actuales. El muestreo de Gibbs gana eficiencia al reducir la aleatoriedad de las propuestas por explotar el conocimiento de la distribución objetivo. :gem: Jaynes dice que *Parece ser un principio bastante general que, siempre que hay una forma aleatoria de hacer algo, entonces hay una forma no aleatoria que ofrece un mejor rendimiento pero requiere más pensamiento.*. Esta forma menos aleatoria puede requerir mucho más pensamiento. El modelo Hamiltonian Monte Carlo es un ejemplo de esto. Este es un método Monte Carlo de cadena de Markov para obtener una secuencia de muestras aleatorias que convergen para ser distribuidas de acuerdo con una distribución de probabilidad objetivo para la cual el muestreo directo es difícil.
