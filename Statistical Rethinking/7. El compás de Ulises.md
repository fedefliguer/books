## 7. EL COMPÁS DE ULISES

* Nicolás Copernico abogó por reemplazar el modeo geocéntrico por uno heliocéntrico, que era más 'armonioso'. Esta historia se ha convertido en una fábula del triunfo de la ciencia sobre la ideología y la superstición. El modelo de Copernico hacía las mismas predicciones que el geocéntrico, pero era más complejo. Dado que en precisión eran equivalentes, había razones para preferir el más simple. En este capítulo se verán los casos en los que la precisión y la simplicidad se compensan, basado en los tres monstruos: el Underfitting, el Overfitting y el Confounding. Nuestro trabajo será ver métodos para no caer en esto: regularización para que el modelo no se emocione demasiado con los datos, o bien métodos como Information Criteria o Cross Validation.

### 7.1. El problema de los parámetros

* Lo que hemos visto hasta ahora es que agregar variables puede ayudar a revelar los efectos causales reales. Hemos visto que agregar variables puede ayudar a predecir mejor, a costa de esconder influencias reales causales. Entonces, si no queremos entender la asociación causal sino predecir, siempre está bien agregar variables?
* El sobreajuste ocurre cuando un modelo aprende demasiado de la muestra. Lo que esto significa es que hay tanto características regulares como irregulares. Las características regulares son los objetivos de nuestro aprendizaje, porque generalizan bien o responden a una pregunta de interés. Las características irregulares son, en cambio, aspectos de los datos que no se generalizan y por lo que puede engañarnos. En el extremo, si tenemos suficientes parámetros para asignar a cada punto de los datos, la asignación será perfecta y el R2 será 1.
* Los modelos polinómicos sobreajustados logran ajustar los datos extremadamente bien, pero sufren por esta precisión dentro de la muestra al hacer predicciones sin sentido fuera de la muestra. Por el contrario, el ajuste insuficiente produce modelos que son inexactos tanto dentro y fuera de la muestra. Han aprendido muy poco, sin poder recuperar las características regulares de la muestra. Otra forma de analizar si los modelos están sobre o subajustados tiene que ver con el cambio en la curva cuando se quitan observaciones. Si el cambio es extremadamente bajo entonces el modelo podría estar subajustado, mientras que si es extremandamente alto podría estar sobreajustado.

### 7.2. Entropía y accuracy

* Entonces, ¿cómo navegamos entre el overfitting y el underfitting? Por un lado, es posible realizar un análisis de costo-beneficio. ¿Cuánto cuesta cuando nos equivocamos? ¿cuanto hacemos ganar cuando tenemos razón? La mayoría de los científicos nunca hacen estas preguntas de manera formal, pero deberíamos responderlas rutinariamente. Se parte de un ejemplo de dos meteorologos para diez días: uno predice 100% de lluvia tres días en los que llueve y 60% de lluvia los otros siete en los que no llueve. El otro predice 0% de lluvia siempre. Así es que el primero acierta 3 * 100% + 7 * 40% = 5.8, mientras el segundo 3 * 0% + 7 * 100% = 7. Si en cambio hicieramos un scoring que asignara puntajes distintos a cada equivocación, el resultado podría ser otro.
* Si en vez de calcular la accuracy por medio de ese score 'parejo' o de scores ponderados, lo hicieramos por medio de la probabilidad conjunta, deberíamos computar las probabilidades de predecir correctamente la secuencia conjunta, es decir 1 * 1 * 1 * 0.4 * 0.4 * 0.4 * 0.4 * 0.4 * 0.4 * 0.4 = 0.005 para el primer caso y 0 * 0 ...  = 0 para el segundo caso. Esta segunda probabilidad 'cuenta casos' como estamos viendo, desde un enfoque bayesiano. Suele llamarse Log Socring Rule, porque habitualmente busca la log-probabilidad de que la predicción sea perfecta. Se trata de hallar la distancia entre la predicción y el verdadero en caso de fallar, lo cual trae consigo el problema de la determinación de la distancia correcta para usar. La solución al problema de cómo medir la distancia de precisión de un modelo desde un objetivo se proporcionó a fines de la década de 1940, con la Teoría de la Información. La idea básica es preguntar: ¿Cuánto se reduce nuestra incertidumbre al conocer un resultado? Considere las previsiones meteorológicas de nuevo. Los pronósticos se emiten con anticipación y el clima es incierto. Cuando llega el día real, el clima ya no es incierto. La reducción en la incertidumbre es entonces una medida natural de cuánto hemos aprendido, cuánta “información” obtenemos al observar el resultado. Entonces, si podemos desarrollar una definición precisa de "incertidumbre", podemos proporcionar una medida de referencia de lo difícil que es predecir. La disminución medida en la incertidumbre es la definición de información en este contexto.
* Para aplicar esto, necesitamos una forma que nos permita cuantificar la incertidumbre inherente a una distribución de probabilidad. Supongamos que hay dos climas posibles: sol o lluvia. Cada uno de estos eventos ocurre con alguna probabilidad, y estas probabilidades suman uno. Lo que queremos es una función. De ella deseamos tres cosas:
    1. Contínua. Así un cambio chico en las probabilidades no resulte en un cambio grande en la incertidumbre.
    2. Creciente con la mayor cantidad de posibles eventos.
    3. Aditiva. Si tenemos múltiples eventos, las incertidumbres deberían poder sumarse.
* Siguiendo estos tres principios surge la función de entropía de la información, en donde si hay n diferentes posibles eventos y cada evento tiene probabilidad p, la medida de incertidumbre es:
$$H(p) = -Elog(p_{i}) = -\sum_{i=1}^{n}p_{i}log(p_{i})$$
lo que significa que la incertidumbre contenida en una distribución de probabilidad es la probabilidad logarítmica promedio de un evento. Si las verdaderas probabilidades fueran 0.3 de lluvia y 0.7 de sol, entonces $H(p) = 0.61$. Si las verdaderas probabilidades fueran 0.01 de lluvia y 0.99 de sol, entonces $H(p) = 0.06$. Estos valores de incertidumbre no dicen mucho por sí mismos, pero nos pueden ayudar a generar medidas de precisión. En el mismo sentido y cómo se verá luego, maximizar la entropía es buscar la distribución más consistente con los datos.
