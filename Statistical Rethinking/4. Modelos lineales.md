## 4. MODELOS LINEALES

* :gem: La teoría ptolomeica de la tierra decía que el sistema solar era geocéntrico, cosa por supuesto falsa, pero sin embargo la estrategia que lo justificó (el uso de epiciclos, el verdadero aporte de ptolomeo) resulta un sistema generalizado de aproximación que hace buenas predicciones.
* Por "regresión lineal" nos referiremos a una familia de golems estadísticos simples que intentan aprender sobre la media y varianza de alguna medida, usando una combinación aditiva de otras medidas. Como el geocentrismo, la regresión lineal puede describir útilmente una gran variedad de fenómenos naturales.

### 4.1. Por qué las distribuciones normales son normales

* La mayoría de los procesos de la naturaleza no son gaussianos o normales. Sin embargo, cualquier proceso que sigue una distribución de probabilidad tiene un promedio, y cualquiera sea el promedio, cada muestra de la distribución puede considerarse como una fluctuación sobre ese valor promedio. Cuando comenzamos a sumar estas fluctuaciones, también comienzan a cancelarse entre sí. Una gran fluctuación positiva cancelará una gran negativa. Cuantos más términos en la suma, más posibilidades de que cada fluctuación sea cancelada por otra o por una serie de otras más pequeñas en la dirección opuesta. 
* El ejemplo típico podría ser un dado (distribución uniforme) pero el promedio de dos dados ya no es uniforme: hay muchas más chances de promedio 3 (4+2, 2+4, 3+3, 1+5, 5+1) que de promedio 6 o promedio 1. Otros efectos a través de la multiplicación o la log-multiplicación también se convierten en normales.
* Entonces, si bien la mayoría de los procesos de la naturaleza no son gaussianos o normales en esencia, muchos provienen de sumas o multiplicacioones de procesos no gaussianos, y se transfomran en gaussianos. Errores de medición, variaciones en el crecimiento y velocidades de moléculas podrían ser ejemplos de esto.
* Las conveniencias de la distribución gaussiana no son únicamente la abundancia en procesos, sino también una conveniencia epistemológica, dado que esta distribución solo necesita una media y una varianza. Es la expresión máxima de la ignorancia, porque es consistente con los supuestos mínimos: si estamos dispuestos a aceptar que nuestra distribución tiene varianza finita, la gaussiana es la más probable. Más bien, para suponer que la distribución no es gaussiana tendríamos que tener información adicional. Esto volverá a aparecer cuando se vea la teoría de la información.
* Sobre la distribución normal: la fórmula es compleja, pero el factor más importante es (y-μ)^2 que da a la distribución una forma cuadrática. El resto de la fórmula únicamente estandariza esto. Además, es la primera de las distribuciones que vemos que es continua, por lo que no tiene una función de masa de probabilidad sino una función de densidad. La densidad de probabilidad es la tasa de cambio en la probabilidad acumulativa, y entonces puede ser mayor a 1. Lo que nunca podrá ser mayor a 1 es el área bajo la curva.

### 4.2. Un lenguaje para describir modelos

* Las decisiones que forman parte de un modelo de este tipo son varias: el conjunto de medidas que esperamos predecir o comprender, es decir el resultado; la distribución de probabilidad de cada observación individual (la pensaremos normal en regresión lineal); cuáles son las variables predictoras; la forma en la que los predictores se relacionan con el resultado; y los priors de los parámetros del modelo.
* Esto es otro lenguaje con el que los problemas pueden describirse. El caso del agua en la tierra, por ejemplo, podría escribirse como un valor w que se distribuye en una biomial(n,p), con p con un prior uniforme entre 0 y 1. Una vez que conocemos el modelo de esta manera, conocemos automáticamente todos sus supuestos, ya que sabemos que la distribución binomial supone que cada muestra (lanzamiento de globo) es independiente de la otra, y también sabemos que el modelo supone que los puntos de muestra son independientes entre sí.

### 4.3. Un modelo gaussiano de altura

* Hay un número infinito de posibles distribuciones gaussianas: algunas tienen medias más chicas o más grandes, varianzas más chicas o más grandes. Para construir un modelo, queremos que nuestra máquina bayesiana considere todas las distribuciones posibles, y clasificarlas por plausibilidad posterior, que es la compatibilidad lógica de cada posible distribución con los datos y el modelo.
```r
library(rethinking) 4.7
data(Howell1) # 544 individuos con su altura (en centímetros), su peso (en kilos), su edad y si son hombres o mujeres.
d <- Howell1
d2 <- d[d$age>=18,] # Filtro adultos
```
* Si nos concentramos únicamente en la altura, vemos que la densidad tiene una forma similar a la normal. Como se trata de una normal, podría ser una acumulación de distribuciones subyacentes, como ya vimos. Pero usemos la distribución normal: ¿cuál hay que usar? necestamos una combinación media-varianza, que no tenemos aún. Por eso escribimos hi~Normal(μ; σ), asumiendo iid: asumiendo que todos los valores tienen igual probabilidad. Es una suposición que muchas veces no parece probable en el mundo físico, pero sí en dentro del modelo.
* Para completar el modelo es necesario generar los priors de nuestros parámetros. μ tendrá una distribución normal(178,20) y σ una uniforme(0,50), definidas en forma arbitraria. Con eso ya podemos calcular, por medio de la aproximación de grilla, la distribución posterior.
```r
flist <- alist( 4.25
height ~ dnorm( mu , sigma ) ,
mu ~ dnorm( 178 , 20 ) ,
sigma ~ dunif( 0 , 50 )
)

m4.1 <- map( flist , data=d2 )
precis( m4.1 )

Mean StdDev 5.5% 94.5%
mu 154.61 0.41 153.95 155.27
sigma 7.73 0.29 7.27 8.20
```
* Estos números proporcionan aproximaciones gaussianas para la distribución marginal de cada parámetro. Esto significa la plausibilidad de cada valor de μ, después de promediar las plausibilidades de cada valor de σ, viene dado por una distribución gaussiana con media 154.6 y desviación estándar 0.4.
