## 1. EL GOLEM DE PRAGA: *modelos estadísticos*

### 1.1. Modelos estadísticos
* :gem: _El golem es un robot de arcilla conocido en el folklore judío, construido a partir de polvo, fuego y agua. Se le da vida al inscribir emet, "verdad", en su frente. Animado en verdad, pero sin voluntad propia, un golem siempre hace exactamente lo que se le dice. Esto es afortunado porque el golem es increíblemente poderoso, capaz de resistir y lograr más de lo que Los creadores podrían. Sin embargo, su obediencia también trae peligro, como instrucciones descuidadas o inesperadas. los eventos pueden convertir a un golem en contra de sus creadores. Su abundancia de poder se corresponde con su falta de sabiduría._
* Del mismo modo, los modelos estadísticos comparten gran parte de esto. La preocupación por la verdad les da vida, pero en sí mismos no so son ni verdaderos ni falsos, ni profetas ni charlatanes. Más bien son **construcciones diseñadas para algún propósito**. Estas construcciones son increíblemente poderosas, cumpliendo diligentemente sus cálculos programados. Los modelos también son robots sin intención propia, que se mueven de acuerdo con las instrucciones miopes que ellos encarnan. No hay sabiduría en el golem. No discierne cuando el contexto es inapropiado por sus respuestas. Simplemente conoce su propio procedimiento, nada más. Simplemente hace lo que se le dice.

### 1.2. Repensando la estadística
* Las estadísticas tienden a ser inflexibles y frágiles. Por inflexible, quiero decir que tienen muy formas limitadas de adaptarse a contextos de investigación únicos. Por frágil, quiero decir que fallan en impredecibles formas cuando se aplica a nuevos contextos. He leído personalmente cientos de usos de la prueba exacta de Fisher en revistas científicas, pero aparte del uso original de Fisher, nunca he visto que se use adecuadamente. Incluso un procedimiento como la regresión lineal ordinaria, que es bastante flexible en muchos sentidos, a veces es frágil.
* Siguiendo a Popper, la ciencia funciona mejor al desarrollar hipótesis que, en principio, son falsables. Entonces quizás los procedimientos estadísticos deberían falsificar hipótesis, si deseamos ser buenos científicos estadísticos. Sin embargo, en muchos casos la ciencia no es descrita por el estándar de falsificación, como Popper reconoció y argumentó. De hecho, **la falsificación deductiva es imposible en casi todos los contextos científicos**. Esto ocurre sobre todo porque:
 1. Los modelos son complejos. Muchos modelos corresponden a la misma hipótesis, y muchas hipótesis corresponden a un solo modelo. Esto hace que la falsificación estricta sea imposible. La diferencia entre hipótesis y modelos depende del concepto de modelos de proceso: la hipótesis es una idea que puede ser vaga respecto del funcionamiento del mundo, de la que se desprende uno (o varios) modelo de procesos sostenidos por esa hipótesis, que pueden probarse por uno (o varios) modelos estadísticos. Como resultado, las relaciones son múltiples en ambas direcciones: hipótesis no implican modelos únicos, y los modelos no implican hipótesis únicas. De este modo, no es la aceptación o rechazo de las hipótesis lo que hace concluir la fuerza de un modelo. _Una razón por la cual los modelos estadísticos corresponden rutinariamente para muchos modelos de proceso detallados diferentes se debe a que dependen de distribuciones como la normal, binomial, Poisson y otras distribuciones exponenciales. La naturaleza ama estas distribuciones porque ama la entropía, y todas las distribuciones familiares exponenciales son distribuciones de entropía máxima._
 2. La medición importa. Incluso cuando pensamos que los datos falsifican un modelo, otro observador debatirá nuestros métodos y medidas. :gem: _El ejemplo de los cisnes es típico: Cuando los españoles descubrieron Australia, vieron cisnes negros y descartaron su hipótesis nula de que todos los cisnes eran blancos._ Todos estaríamos de acuerdo en que un cisne es blanco o negro, ya que hay pocos tonos intermedios. Pero este tipo de ejemplo es poco común en la ciencia, en donde nos enfrentamos habitualmente a contextos en los que no estamos seguros de si tenemos un resultado desconfirmador. Falsos positivos y falsos negativos pueden aparecer, al igual que problemas de medición, haciendo que el ideal del Popper ceda ante el dilema de la falsación real o espuria. Una revisión de la historia de la ciencia muestra que estos problemas son la norma, no la excepción de la ciencia. El ejemplo de los cisnes, sin embargo, podría falsearse en forma fácil pero si se reemplazar la hipótesis nula por 'el 80% de los cisnes son blancos', entonces la sola visualización de uno no falsearía. En estos casos, la falsificación se une con métodos estadísticos. En estos casos, y en el general de algunas disciplinas como las ciencias sociales, la falsifiación es consensual y no absoluta.
 
 ### 1.3. Tres herramientas para la ingeniería de modelos
* Si la falsación no sirve en el caso de los modelos estadísticos, ¿qué se puede hacer? El modelo estadístico aplicado a principios del siglo XXI está marcado por el uso intensivo de herramientas de ingeniería que casi siempre están ausentes los cursos introductorios e incluso, en algunos intermedios de estadística.

 #### 1.3.1. Análisis de datos bayesianos
 * :gem: _Los griegos y los romanos creían que la sabiduría y la oportunidad (la suerte) eran enemigas. La única constante es la sabiduría, la oportunidad en cambio era cambiante._ La inferencia estadística nos obliga a usar el azar y la incertidumbre para descubrir conocimiento. El análisis de datos bayesianos lo abraza más plenamente, utilizando el lenguaje del azar para describir la plausibilidad de diferentes posibilidades.
* En términos modestos, la inferencia bayesiana no es más que **contar la cantidad de formas en que las cosas pueden suceder**, de acuerdo con nuestras suposiciones. La probabilidad bayesiana es un enfoque muy general de la probabilidad, y se contrapone con el enfoque frecuentista que requiere que todas las probabilidades se definan por conexión a eventos contables y sus frecuencias en muestras muy grandes: los frecuentistas creen que los parámetros y modelos no pueden tener distribuciones de probabilidad, solo las mediciones pueden.
* Ejemplo de frecuentistas y bayesianos: :gem: _En el año 1610, Galileo apuntó un telescopio al cielo de la noche, y se convirtió en el primer humano en ver los anillos de Saturno. Como el telescopio era primitivo, no podía realmente enfocar la imagen muy bien. Saturno siempre parecía borroso._ Es un problema estadístico: existe incertidumbre sobre la forma del planeta, pero la incertidumbres no es resultado de la variación en mediciones repetidas. Podríamos mirar a través del telescopio mil veces, y siempre dará la misma imagen borrosa, por lo que la distribución de muestreo de cualquier medición es constante. La inferencia frecuentista tiene muchos problemas para comenzar aquí. En contraste, la inferencia bayesiana procede como siempre, porque el "ruido" determinista todavía se puede modelar usando la probabilidad.
* En la regresión, las diferencias entre frecuentistas y bayesianos son menores. Más generalmente, los golems bayesianos tratan la "aleatoriedad" como una propiedad de la información, no del mundo. Presumiblemente, si tuviéramos más información, podríamos predecir exactamente todo.

 #### 1.3.2. Modelos multinivel
* En ocasiones, la forma en la que el modelo obtiene el valor de sus parámetros se modeliza también, incrustando un nuevo modelo (el de la forma de obtener los parámetros) en uno viejo: este nuevo modelo tiene **múltiples niveles de incertidumbre**, y se denomina modelo multinivel. Al igual que el análisis de datos bayesianos, el modelado multinivel no es particularmente nuevo, pero la disponibilidad técnica lo revalorizó en los últimos tiempos.
* Cuatro razones se imponen para usar este tipo de modelos:
 1. Para ajustar las estimaciones para el muestreo repetido. Cuando surge más de una observación del mismo individuo, ubicación u hora, los modelos uni-nivel pueden engañarnos.
 2. Si nuestras preguntas de investigación incluyen variación entre individuos u otros grupos dentro de los datos.
 3. Para evitar el promedio. Con frecuencia, los académicos pre-promedian algunos datos para construir variables para un análisis de regresión.
* Se trata, en síntesis, de contextos en los que el investigador reconoce grupos o grupos de mediciones. Ya que cada grupo puede tener una tendencia promedio diferente o responder de manera diferente a cualquier tratamiento, los datos agrupados a menudo se benefician de ser modelados por un golem que espera tal variación. Modelos para datos faltantes (imputación), medición de error, análisis factorial, algunos modelos de series temporales, tipos de regresión espacial y de red, y regresiones filogenéticas.
* Hasta cierto punto estos modelos presentan ventajas que puede decirse que la regresión multinivel merece ser la forma predeterminada de la regresión. Incluso los tratamientos bien controlados interactúan con aspectos no medidos de los individuos, grupos o poblaciones, por lo que el efecto del tratamiento no se logra cuantificar del todo. El multinivel, inspirador del partial pooling y (creo) del bootstrap, llega a cuantificar esto.

 #### 1.3.3. Comparación de modelos
* El análisis de los modelos en forma comparativa tiene que ver con la teoría de la información, o los criterios de información, quizá lo más joven dentro de esta disciplina. 
* El criterio de información de Akaike (AIC), por ejemplo, es una medida de la calidad relativa de un modelo estadístico para un conjunto dado de datos. El AIC es una **medida de la calidad de los modelos**, en la medida que maneja un trade-off entre la bondad de ajuste del modelo y la complejidad del modelo.
* Se basa en la entropía de información: se ofrece una estimación relativa de la información perdida cuando se utiliza un modelo determinado para representar el proceso que genera los datos. No proporciona una prueba de un modelo en el sentido de probar una hipótesis nula, es decir AIC no puede decir nada acerca de la calidad del modelo en un sentido absoluto. Si todos los modelos candidatos encajan mal, AIC no dará ningún aviso de ello.

 #### 1.3.4. Comparación de modelos
* Un modelo estadístico nunca es suficiente para inferir la causa, porque el modelo estadístico no distingue entre el viento que hace que las ramas se balanceen y las ramas que hacen que el viento sople.
* Incluso, los modelos que son causalmente incorrectos pueden mejorar predicciones que las que son causalmente correctas. Como resultado, centrarse en la predicción puede engañarnos sistemáticamente. Llamaremos a esto el problema de la identificación y lo distinguiremos cuidadosamente del problema de la predicción en bruto. Considere dos significados diferentes de "predicción".
* Dentro de lo que es predicción, hay dos problemas distintos:
 1. Cuando somos observadores externos simplemente tratando de adivinar qué sucederá a continuación, las herramientas como la validación cruzada son muy útiles: después de todo, si miras afuera y ves ramas balanceándose, realmente predice viento. La predicción exitosa no requiere una identificación causal correcta.
 2. Pero, ¿qué sucede cuando intervenimos en el mundo? Supongamos que reclutamos a muchas personas para trepar a los árboles y balancear las ramas. ¿Hará viento? Poco. A menudo, el objetivo del modelado estadístico es producir una comprensión que conduzca a la generalización y la aplicación. En ese caso, necesitamos algo más que buenas predicciones, en ausencia de intervención. También necesitamos una comprensión causal precisa.
* Entonces, ¿qué puede hacerse en estos casos? un modelo científico completo contiene más información que un modelo estadístico derivado de ella. Y esta información adicional contiene implicaciones causales. La mayoría de los científicos hacen un uso informal de estas implicaciones. Pero también es posible hacer un uso formal de ellos, demostrando lógicamente cuando una estimación identifica una relación causal. Estos métodos formales datan de la primera mitad del siglo XX, pero se han extendido más recientemente al estudio de la medición, el diseño experimental y la capacidad de generalizar (o transportar) resultados entre muestras. Y la muy buena noticia es que incluso no teniendo un modelo causal completo, sino solo uno heurístico que indica qué variables influyen causalmente en otras, aún puede hacer uso de estas herramientas lógicas. Esa es la estrategia que usaremos en este libro. Usaremos un modelo causal gráfico para representar una hipótesis causal. El modelo causal gráfico más simple es un gráfico acíclico dirigido, generalmente llamado DAG.
