_[Statistical Rethinking: A Bayesian Course with Examples in R and Stan. Richard McElreath](https://github.com/rmcelreath/statrethinking_winter2019)_

## 0. Prefacio

* Este libro busca ayudar a aumentar el conocimiento y la confianza en el modelado estadístico. Se entiende como un andamio, uno que permitirá construir el muro de la materia. En este proceso, se realiza trabajo 'inconveniente' como el paso a paso de algunos algoritmos que luego serán calculados automáticamente.
* El libro busca que el lector esté listo para intentar hacer inferencia estadística sin p-valores.
* El libro cuenta con cuadros 'rethinking' (aluden a conexiones con otros enfoques, proporcionan antecedentes históricos o llaman
malentendidos comunes) y cuadros 'overthinking' (proporcionan más detalles de explicaciones de código o matemáticas).

``` r
install.packages(c("rstan","coda","mvtnorm","devtools"))
library(devtools)
devtools::install_github("rmcelreath/rethinking")
```

## 1. EL GOLEM DE PRAGA: *modelos estadísticos*

### 1.1. Modelos estadísticos
* :gem: _El golem es un robot de arcilla conocido en el folklore judío, construido a partir de polvo, fuego y agua. Se le da vida al inscribir emet, "verdad", en su frente. Animado en verdad, pero sin voluntad propia, un golem siempre hace exactamente lo que se le dice. Esto es afortunado porque el golem es increíblemente poderoso, capaz de resistir y lograr más de lo que Los creadores podrían. Sin embargo, su obediencia también trae peligro, como instrucciones descuidadas o inesperadas. los eventos pueden convertir a un golem en contra de sus creadores. Su abundancia de poder se corresponde con su falta de sabiduría._
* Del mismo modo, los modelos estadístico comparten gran parte de esto. La preocupación por la verdad les da vida, pero en sí mismos no so son ni verdaderos ni falsos, ni profetas ni charlatanes. Más bien son construcciones diseñadas para algún propósito. Estas construcciones
son increíblemente poderosas, cumpliendo diligentemente sus cálculos programados. Los modelos también son robots sin intención propia, que se mueven de acuerdo con las instrucciones miopes que ellos encarnan. No hay sabiduría en el golem. No discierne cuando el contexto es inapropiado por sus respuestas. Simplemente conoce su propio procedimiento, nada más. Simplemente hace lo que se le dice.

### 1.2. Repensando la estadística
* Las estadísticas tienden a ser inflexibles y frágiles. Por inflexible, quiero decir que tienen muy formas limitadas de adaptarse a contextos de investigación únicos. Por frágil, quiero decir que fallan en impredecibles formas cuando se aplica a nuevos contextos. He leído personalmente cientos de usos de la prueba exacta de Fisher en revistas científicas, pero aparte del uso original de Fisher, nunca he visto que se use adecuadamente. Incluso un procedimiento como la regresión lineal ordinaria, que es bastante flexible en muchos sentidos, pudiendo codificar una gran diversidad de hipótesis interesantes, a veces es frágil.
* Siguiendo a Popper, la ciencia funciona mejor al desarrollar hipótesis que, en principio, son falsificables. Entonces quizás los procedimientos estadísticos deberían falsificar hipótesis, si deseamos ser buenos científicos estadísticos. Sin embargo, en muchos casos la ciencia no es descrita por el estándar de falsificación, como Popper reconoció y argumentó. De hecho, la falsificación deductiva es imposible en casi todos los contextos científicos. Esto ocurre sobre todo porque:
 1. Los modelos son complejos. Muchos modelos corresponden a la misma hipótesis, y muchas hipótesis corresponden a un solo modelo. Esto hace que la falsificación estricta sea imposible. La diferencia entre hipótesis y modelos depende del concepto de modelos de proceso: la hipótesis es una idea que puede ser vaga respecto del funcionamiento del mundo, de la que se desprende uno (o varios) modelo de procesos sostenidos por esa hipótesis, que pueden probarse por uno (o varios) modelos estadísticos. Como resultado, las relaciones son múltiples en ambas direcciones: hipótesis no implican modelos únicos, y los modelos no implican hipótesis únicas. De este modo, no es la aceptación o rechazo de las hipótesis lo que hace concluir la fuerza de un modelo. _Una razón por la cual los modelos estadísticos corresponden rutinariamente para muchos modelos de proceso detallados diferentes se debe a que dependen de distribuciones como la normal, binomial, Poisson y otras distribuciones exponenciales. La naturaleza ama estas distribuciones porque ama la entropía, y todas las distribuciones familiares exponenciales son distribuciones de entropía máxima._
 2. La medición importa. Incluso cuando pensamos que los datos falsifican un modelo, otro observador debatirá nuestros métodos y medidas. :gem: _El ejemplo de los cisnes es típico: Cuando los españoles descubrieron Australia, vieron cisnes negros y descartaron su hipótesis nula de que todos los cisnes eran blancos._ Todos estaríamos de acuerdo en que un cisne es blanco o negro, ya que hay pocos tonos intermedios. Pero este tipo de ejemplo es poco común en la ciencia, en donde nos enfrentamos habitualmente a contextos en los que no estamos seguros de si tenemos un resultado desconfirmador. Falsos positivos y falsos negativos pueden aparecer, al igual que problemas de medición, haciendo que el ideal del Popper ceda ante el dilema de la falsación real o espuria. Una revisión de la historia de la ciencia muestra que estos problemas son la norma, no la excepción de la ciencia. El ejemplo de los cisnes, sin embargo, podría falsearse en forma fácil pero si se reemplazar la hipótesis nula por 'el 80% de los cisnes son blancos', entonces la sola visualización de uno no falsearía. En estos casos, la falsificación se une con métodos estadísticos. En estos casos, y en el general de algunas disciplinas como las ciencias sociales, la falsifiación es consensual y no absoluta.
 
 ### 1.3. Tres herramientas para la ingeniería de modelos
* Si la falsación no sirve en el caso de los modelos estadísticos, ¿qué se puede hacer? El modelo estadístico aplicado a principios del siglo XXI está marcado por el uso intensivo de herramientas de ingeniería que casi siempre están ausentes los cursos introductorios e incluso, en algunos intermedios de estadística.

 #### 1.3.1. Análisis de datos bayesianos
 * :gem: _Los griegos y los romanos creían que la sabiduría y la oportunidad (la suerte) eran enemigas. La única constante es la sabiduría, la oportunidad en cambio era cambiante._ La inferencia estadística nos obliga a usar el azar y la incertidumbre para descubrir conocimiento. El análisis de datos bayesianos lo abraza más plenamente, utilizando el lenguaje del azar para describir la plausibilidad de diferentes posibilidades.
* En términos modestos, la inferencia bayesiana no es más que contar la cantidad de formas en que las cosas pueden suceder, de acuerdo con nuestras suposiciones. La probabilidad bayesiana es un enfoque muy general de la probabilidad, y se contrapone con el enfoque frecuentista que requiere que todas las probabilidades se definan por conexión a eventos contables y sus frecuencias en muestras muy grandes: los frecuentistas creen que los parámetros y modelos no pueden tener distribuciones de probabilidad, solo las mediciones pueden.
* Ejemplo de frecuentistas y bayesianos: :gem: _En el año 1610, Galileo apuntó un telescopio al cielo de la noche, y se convirtió en el primer humano en ver los anillos de Saturno. Como el telescopio era primitivo, no podía realmente enfocar la imagen muy bien. Saturno siempre parecía borroso._ Es un problema estadístico: existe incertidumbre sobre la forma del planeta, pero la incertidumbres no es resultado de la variación en mediciones repetidas. Podríamos mirar a través del telescopio mil veces, y siempre dará la misma imagen borrosa, por lo que la distribución de muestreo de cualquier medición es constante. La inferencia frecuentista tiene muchos problemas para comenzar aquí. En contraste, la inferencia bayesiana procede como siempre, porque el "ruido" determinista todavía se puede modelar usando la probabilidad.
* En la regresión, las diferencias entre frecuentistas y bayesianos son menores. Más generalmente, los golems bayesianos tratan la "aleatoriedad" como una propiedad de la información, no del mundo. Presumiblemente, si tuviéramos más información, podríamos predecir exactamente todo.

 #### 1.3.2. Modelos multinivel
* En ocasiones, la forma en la que el modelo obtiene el valor de sus parámetros se modeliza también, incrustando un nuevo modelo (el de la forma de obtener los parámetros) en uno viejo: este nuevo modelo tiene múltiples niveles de incertidumbre, y se denomina modelo multinivel. Al igual que el análisis de datos bayesianos, el modelado multinivel no es particularmente nuevo, pero la disponibilidad técnica lo revalorizó en los últimos tiempos.
* Cuatro razones se imponen para usar este tipo de modelos:
 1. Para ajustar las estimaciones para el muestreo repetido. Cuando surge más de una observación del mismo individuo, ubicación u hora, los modelos uni-nivel pueden engañarnos.
 2. Si nuestras preguntas de investigación incluyen variación entre individuos u otros grupos dentro de los datos.
 3. Para evitar el promedio. Con frecuencia, los académicos pre-promedian algunos datos para construir variables para un análisis de regresión.
* Se trata, en síntesis, de contextos en los que el investigador reconoce grupos o grupos de mediciones. Ya que cada grupo puede tener una tendencia promedio diferente o responder de manera diferente a cualquier tratamiento, los datos agrupados a menudo se benefician de ser modelados por un golem que espera tal variación. Modelos para datos faltantes (imputación), medición de error, análisis factorial, algunos modelos de series temporales, tipos de regresión espacial y de red, y regresiones filogenéticas.

 #### 1.3.3. Comparación de modelos
* El análisis de los modelos en forma comparativa tiene que ver con la teoría de la información, o los criterios de información, quizá lo más joven dentro de esta disciplina. 
* El criterio de información de Akaike (AIC), por ejemplo, es una medida de la calidad relativa de un modelo estadístico para un conjunto dado de datos. El AIC es una medida de la calidad de los modelos, en la medida que maneja un trade-off entre la bondad de ajuste del modelo y la complejidad del modelo.
* Se basa en la entropía de información: se ofrece una estimación relativa de la información perdida cuando se utiliza un modelo determinado para representar el proceso que genera los datos. No proporciona una prueba de un modelo en el sentido de probar una hipótesis nula, es decir AIC no puede decir nada acerca de la calidad del modelo en un sentido absoluto. Si todos los modelos candidatos encajan mal, AIC no dará ningún aviso de ello.

## 2. MUNDOS CHICOS Y MUNDOS GRANDES: *teoría de la probabilidad*

* :gem: A diferencia de Cristobal Colón que pensó que el mundo, de acuerdo a sus conocimientos, era mucho más chico de lo que realmente era, el desafío estadístico principal es tratar de que la navegación entre el mundo de lo que se conoce al realizar el modelo al mundo de lo que aún no se conoce, sea lo más tranquila posible. 
* Asumiendo que el mundo pequeño es una descripción precisa del mundo real, los modelos bayesianos son los mejores. Sin embargo, la efectividad del modelo es jústamente su capacidad de predicción en el mundo grande, el exterior: a diferencia del pequeño, la efectividad en el mundo grande tiene que demostrarse en lugar de deducirse lógicamente. 
* Este capítulo, que explica la teoría de la probabilidad en su esencia, se centra en el mundo pequeño. Es la base para el próximo en el que se verá el mundo grande.

_Pag 20
